# ğŸ“– Glossar & BegriffserklÃ¤rungen

Dieses Glossar erklÃ¤rt wichtige Begriffe, Methoden und Metriken aus dem Projekt â€Degrees of No Returnâ€œ in verstÃ¤ndlicher Sprache. Es dient als Nachschlagewerk fÃ¼r alle, die tiefer in die Materie eintauchen mÃ¶chten, ohne Data-Science-Experten zu sein.

## ğŸŒ¡ï¸ Klimatologische Begriffe

**Hitzetag**
Ein meteorologischer Begriff. Ein Tag gilt dann als Hitzetag, wenn die **TageshÃ¶chsttemperatur 30â€¯Â°C erreicht oder Ã¼berschreitet**. In unseren Modellen prognostizieren wir die jÃ¤hrliche Anzahl dieser Tage, da sie ein direkter Indikator fÃ¼r Gesundheitsrisiken und stÃ¤dtische Hitzeinseln sind.

**Emissionspfade (Szenarien)**
Zukunftsprojektionen darÃ¼ber, wie viel Treibhausgas die Menschheit in den kommenden Jahren ausstoÃŸen wird. Das Projekt unterscheidet oft zwischen einem â€Weiter-wie-bisherâ€œ-Szenario (hohe Emissionen) und einem â€Klimazielâ€œ-Szenario (starke Reduktion der Emissionen).

**Downscaling**
Das "Herunterrechnen" von globalen Daten auf eine lokale Ebene. Ein globales Klimamodell sagt vielleicht vorher, dass die Erde im Schnitt 1 Grad wÃ¤rmer wird. Downscaling berechnet, was das *konkret* fÃ¼r z.B. Berlin oder MÃ¼nchen bedeutet (da sich Landmassen schneller erwÃ¤rmen als Ozeane).

---

## ğŸ¤– Machine Learning & Data Science (Die â€A-Phasenâ€œ)

**Algorithmus**
In unserem Kontext ein â€Rezeptâ€œ fÃ¼r den Computer. Es ist eine Rechenvorschrift, die aus Daten lernt. Wir testen verschiedene Algorithmen (z.B. *Lineare Regression*, *Random Forest*), um zu sehen, welcher die ZusammenhÃ¤nge zwischen COâ‚‚ und Temperatur am besten versteht.

**Training & Testen**
Wir geben dem Modell nie *alle* Daten zum Lernen. Wir behalten einen Teil (die jÃ¼ngsten Jahre) zurÃ¼ck (â€Testdatenâ€œ). Das Modell lernt mit den alten Daten (â€Trainingsdatenâ€œ) und muss dann beweisen, dass es die Testdaten korrekt vorhersagen kann, ohne sie vorher gesehen zu haben.

**Features (Merkmale)**
Die â€Zutatenâ€œ, mit denen wir das Modell fÃ¼ttern.
*   *Beispiel:* Um die Temperatur von morgen vorherzusagen, kÃ¶nnten Features sein: â€Temperatur heuteâ€œ, â€COâ‚‚-Konzentration aktuellâ€œ, â€Jahreszeitâ€œ.
*   **Lag-Features (VerzÃ¶gerung):** Ein spezielles Feature. Da das Klima trÃ¤ge ist (wie ein schwerer GÃ¼terzug), wirkt sich COâ‚‚ von heute erst spÃ¤ter voll aus. Lag-Features berÃ¼cksichtigen diese VerzÃ¶gerung (z.B. â€COâ‚‚-Wert von vor 10 Jahrenâ€œ).

**Hyperparameter**
Die â€Einstellungen am Backofenâ€œ. WÃ¤hrend der Algorithmus das Rezept ist, sind Hyperparameter die Feinjustierungen (z.B. wie schnell soll das Modell lernen? Wie komplex darf die Formel sein?). Wir optimieren diese, um das bestmÃ¶gliche Ergebnis zu erzielen.

**Overfitting (Ãœberanpassung)**
Ein hÃ¤ufiges Problem. Das Modell lernt die Trainingsdaten *zu* gut auswendig, anstatt die allgemeinen Regeln zu verstehen.
*   *Metapher:* Ein SchÃ¼ler, der die LÃ¶sungen fÃ¼r die Mathe-Hausaufgabe auswendig lernt, aber in der Klassenarbeit (neue Aufgaben) versagt. Wir vermeiden das durch Techniken wie *Cross-Validation*.

---

## ğŸ“Š MessgrÃ¶ÃŸen der Genauigkeit

**RMSE (Root Mean Square Error)**
Unser wichtigstes MaÃŸ fÃ¼r die Genauigkeit bei Temperaturvorhersagen.
*   Er gibt an, um wie viel Grad das Modell im Durchschnitt daneben liegt.
*   **Ziel:** Wir wollen einen RMSE von unter **0,2â€¯Â°C**. Das bedeutet, unsere Vorhersage weicht durchschnittlich weniger als 0,2 Grad vom tatsÃ¤chlichen Wert ab.

**RÂ² (BestimmtheitsmaÃŸ)**
Ein Wert zwischen 0 und 1 (oder 0% und 100%). Er sagt aus, wie viel Prozent der Schwankungen in den Daten unser Modell erklÃ¤ren kann.
*   Ein RÂ² von 0,95 bedeutet: Das Modell erklÃ¤rt 95% der TemperaturverÃ¤nderungen korrekt.

---

## ğŸ”„ Prozessmodell: QUAÂ³CK

Wir arbeiten nach dem **QUAÂ³CK-Prozessmodell** (gesprochen: "Quack"). Es ist unser strukturierter Fahrplan, um von der ersten Idee zur fertigen Anwendung zu gelangen. Das "Hoch 3" steht fÃ¼r die drei intensiven Entwicklungsphasen im Bereich Machine Learning.

**Q â€“ Question (Fragestellung)**
*   Am Anfang steht das "Warum?". Wir definieren das konkrete Problem, die Zielgruppe (z.B. Stadtplaner) und die Erfolgskriterien.
*   *Ziel:* Ein klares VerstÃ¤ndnis davon, was wir lÃ¶sen wollen (z.B. "Wie heiÃŸ wird es 2050 in Berlin?").

**U â€“ Understanding the Data (DatenverstÃ¤ndnis)**
*   Bevor wir modellieren, mÃ¼ssen wir unsere Daten kennenlernen. Wir prÃ¼fen QualitÃ¤t, Ursprung und Verteilung.
*   *Ziel:* Sicherstellen, dass unsere Datenbasis ("Single Source of Truth") sauber und vertrauenswÃ¼rdig ist.

**A1 â€“ Algorithm Selection (Algorithmenauswahl)**
*   Die Suche nach dem passenden Werkzeug. Testen verschiedener Modelle (z.B. Lineare Regression vs. Random Forest).
*   *Ziel:* Den Algorithmus finden, der unser Problem am besten lÃ¶sen kann.

**A2 â€“ Adapting Features (Feature-Anpassung)**
*   Datenaufbereitung fÃ¼r Fortgeschrittene. Wir transformieren Rohdaten so, dass das Modell sie besser versteht (z.B. durch "Lag-Features" oder zeitliche Synchronisierung).
*   *Ziel:* Den Rohdiamanten schleifen, damit das Modell Muster leichter erkennt.

**A3 â€“ Adjusting Hyperparameters (Hyperparameter-Optimierung)**
*   Feinjustierung. Wir drehen an den Stellschrauben des gewÃ¤hlten Modells, um das letzte QuÃ¤ntchen Genauigkeit herauszuholen (z.B. RMSE unter 0,2â€¯Â°C drÃ¼cken).
*   *Ziel:* Maximale Performance und Robustheit.

**C â€“ Conclusion & Compare (Schlussfolgerung)**
*   Der RealitÃ¤tscheck. Wir bewerten das fertig trainierte Modell kritisch und vergleichen es mit Alternativen.
*   *Ziel:* Die Entscheidung fÃ¼r das finale Modellsetup, das in die App kommt.

**K â€“ Knowledge Transfer (Wissenstransfer)**
*   Vom Code zur Anwendung. Wir bauen die Streamlit-Web-App und dokumentieren unsere Ergebnisse verstÃ¤ndlich.
*   *Ziel:* Die komplexen Ergebnisse fÃ¼r den Endnutzer nutzbar machen (Dashboard, Karten, KPIs).
