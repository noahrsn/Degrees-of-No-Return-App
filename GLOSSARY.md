# ğŸ“– Glossar & BegriffserklÃ¤rungen

Dieses Glossar erklÃ¤rt wichtige Begriffe, Methoden und Metriken aus dem Projekt â€Degrees of No Returnâ€œ in verstÃ¤ndlicher Sprache. Es dient als Nachschlagewerk fÃ¼r alle, die tiefer in die Materie eintauchen mÃ¶chten, ohne Data-Science-Experten zu sein.

## ğŸŒ¡ï¸ Klimatologische Begriffe

**Hitzetag**
Ein meteorologischer Begriff. Ein Tag gilt dann als Hitzetag, wenn die **TageshÃ¶chsttemperatur 30â€¯Â°C erreicht oder Ã¼berschreitet**. In unseren Modellen prognostizieren wir die jÃ¤hrliche Anzahl dieser Tage, da sie ein direkter Indikator fÃ¼r Gesundheitsrisiken und stÃ¤dtische Hitzeinseln sind.
*   *Quelle:* [Deutscher Wetterdienst (DWD) - Wetterlexikon: Hitzetag](https://www.dwd.de/DE/service/lexikon/Functions/glossar.html?lv2=101094&lv3=101192)

**Emissionspfade (Szenarien / SSPs)**
Zukunftsprojektionen darÃ¼ber, wie viel Treibhausgas die Menschheit in den kommenden Jahren ausstoÃŸen wird. Die Wissenschaft nutzt dafÃ¼r sogenannte *Shared Socioeconomic Pathways (SSPs)*. Das Projekt unterscheidet oft zwischen einem â€Weiter-wie-bisherâ€œ-Szenario (hohe Emissionen, z.B. SSP5-8.5) und einem â€Klimazielâ€œ-Szenario (starke Reduktion der Emissionen, z.B. SSP1-2.6).
*   *Quelle:* [IPCC (Intergovernmental Panel on Climate Change) - AR6 Scenarios](https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_Chapter_01.pdf)

**Downscaling**
Das "Herunterrechnen" von globalen Daten auf eine lokale Ebene. Ein globales Klimamodell sagt vielleicht vorher, dass die Erde im Schnitt 1 Grad wÃ¤rmer wird. Downscaling berechnet, was das *konkret* fÃ¼r z.B. Berlin oder MÃ¼nchen bedeutet (da sich Landmassen schneller erwÃ¤rmen als Ozeane und lokale Topografie eine Rolle spielt).
*   *Quelle:* [Climate Data Guide (NCAR) - Statistical Downscaling](https://climatedataguide.ucar.edu/climate-data/statistical-downscaling)

**Temperaturanomalie**
Die Abweichung der Temperatur von einem langjÃ¤hrigen Durchschnittswert (Referenzperiode, z.B. 1951â€“1980). In der Klimaforschung arbeitet man fast ausschlieÃŸlich mit Anomalien statt mit absoluten Temperaturen, da diese robuster gegenÃ¼ber Messfehlern einzelner Stationen sind und globale Trends besser abbilden.
*   *Quelle:* [NASA Earth Observatory - Why Anomalies?](https://earthobservatory.nasa.gov/world-of-change/DecadalTemp)

---

## ğŸ¤– Machine Learning & Data Science (Die â€A-Phasenâ€œ)

**Algorithmus**
In unserem Kontext ein â€Rezeptâ€œ fÃ¼r den Computer. Es ist eine mathematische Rechenvorschrift, die aus historischen Daten lernt. Wir testen verschiedene Algorithmen (z.B. *Lineare Regression*, *Random Forest*), um zu sehen, welcher die ZusammenhÃ¤nge zwischen COâ‚‚ und Temperatur am besten versteht.
*   *Quelle:* [IBM - What is Machine Learning?](https://www.ibm.com/topics/machine-learning)

**Training & Testen (Train-Test-Split)**
Wir geben dem Modell nie *alle* Daten zum Lernen. Wir behalten einen Teil (z.B. die jÃ¼ngsten 20% der Jahre) zurÃ¼ck (â€Testdatenâ€œ). Das Modell lernt mit den alten Daten (â€Trainingsdatenâ€œ) und muss dann beweisen, dass es die Testdaten korrekt vorhersagen kann, ohne sie vorher gesehen zu haben. Dies verhindert, dass das Modell die Daten nur auswendig lernt.
*   *Quelle:* [Scikit-Learn Documentation - Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html)

**Features (Merkmale)**
Die â€Zutatenâ€œ, mit denen wir das Modell fÃ¼ttern. Es sind die messbaren Eigenschaften, die zur Vorhersage genutzt werden.
*   *Beispiel:* Um die Temperatur von morgen vorherzusagen, kÃ¶nnten Features sein: â€Temperatur heuteâ€œ, â€COâ‚‚-Konzentration aktuellâ€œ.
*   **Lag-Features (VerzÃ¶gerung):** Ein spezielles Feature. Da das Klima trÃ¤ge ist (wie ein schwerer GÃ¼terzug), wirkt sich COâ‚‚ von heute erst spÃ¤ter voll aus. Lag-Features berÃ¼cksichtigen diese VerzÃ¶gerung (z.B. â€COâ‚‚-Wert von vor 5 Jahrenâ€œ).
*   *Quelle:* [Machine Learning Mastery - Feature Engineering for Time Series](https://machinelearningmastery.com/basic-feature-engineering-time-series-data-python/)

**Hyperparameter**
Die â€Einstellungen am Backofenâ€œ. WÃ¤hrend der Algorithmus das Rezept ist, sind Hyperparameter die Feinjustierungen, die *vor* dem Training festgelegt werden mÃ¼ssen (z.B. wie stark soll das Modell bestraft werden, wenn es zu komplex wird? = `alpha` bei der Ridge-Regression). Wir optimieren diese systematisch (z.B. per Grid Search), um das bestmÃ¶gliche Ergebnis zu erzielen.
*   *Quelle:* [Towards Data Science - Understanding Hyperparameters](https://towardsdatascience.com/understanding-hyperparameters-and-its-optimisation-techniques-f0debba07568)

**Overfitting (Ãœberanpassung) & Data Leakage**
*   **Overfitting:** Das Modell lernt die Trainingsdaten *zu* gut auswendig (inklusive Rauschen und Fehlern), anstatt die allgemeinen Regeln zu verstehen. Es versagt dann bei neuen Daten.
*   **Data Leakage:** Ein schwerer Fehler, bei dem Informationen aus den Testdaten versehentlich ins Training flieÃŸen (z.B. durch falsches Skalieren vor dem Aufteilen). Das Modell "schummelt" und wirkt besser, als es ist.
*   *Quelle:* [Kaggle - Data Leakage](https://www.kaggle.com/code/alexisbcook/data-leakage)

---

## ğŸ“Š MessgrÃ¶ÃŸen der Genauigkeit

**RMSE (Root Mean Square Error)**
Unser wichtigstes MaÃŸ fÃ¼r die Genauigkeit bei Temperatur- und Meeresspiegelvorhersagen.
*   Er berechnet die Wurzel aus dem Durchschnitt der quadrierten Vorhersagefehler.
*   Er gibt an, um wie viel Grad (oder cm) das Modell im Durchschnitt daneben liegt. GroÃŸe AusreiÃŸer werden durch das Quadrieren stÃ¤rker bestraft.
*   **Ziel:** Wir wollen einen RMSE von unter **0,2â€¯Â°C**. Das bedeutet, unsere Vorhersage weicht durchschnittlich weniger als 0,2 Grad vom tatsÃ¤chlichen Wert ab.
*   *Quelle:* [Statology - RMSE](https://www.statology.org/root-mean-square-error-python/)

**RÂ² (BestimmtheitsmaÃŸ / R-Squared)**
Ein statistischer Wert zwischen 0 und 1 (oder 0% und 100%). Er sagt aus, wie viel Prozent der Varianz (Schwankungen) in der ZielgrÃ¶ÃŸe durch unser Modell erklÃ¤rt werden kann.
*   Ein RÂ² von 0,95 bedeutet: Das Modell erklÃ¤rt 95% der TemperaturverÃ¤nderungen korrekt durch die eingegebenen Features (wie COâ‚‚).
*   *Quelle:* [Investopedia - R-Squared](https://www.investopedia.com/terms/r/r-squared.asp)

---

## ğŸ”„ Prozessmodell: QUAÂ³CK

Wir arbeiten nach dem **QUAÂ³CK-Prozessmodell** (gesprochen: "Quack"). Es ist unser strukturierter Fahrplan, um von der ersten Idee zur fertigen Anwendung zu gelangen. Das "Hoch 3" steht fÃ¼r die drei intensiven Entwicklungsphasen im Bereich Machine Learning.

**Q â€“ Question (Fragestellung)**
*   Am Anfang steht das "Warum?". Wir definieren das konkrete Problem, die Zielgruppe (z.B. Stadtplaner) und die Erfolgskriterien.
*   *Ziel:* Ein klares VerstÃ¤ndnis davon, was wir lÃ¶sen wollen (z.B. "Wie heiÃŸ wird es 2050 in Berlin?").

**U â€“ Understanding the Data (DatenverstÃ¤ndnis)**
*   Bevor wir modellieren, mÃ¼ssen wir unsere Daten kennenlernen. Wir prÃ¼fen QualitÃ¤t, Ursprung und Verteilung.
*   *Ziel:* Sicherstellen, dass unsere Datenbasis ("Single Source of Truth") sauber und vertrauenswÃ¼rdig ist.

**A1 â€“ Algorithm Selection (Algorithmenauswahl)**
*   Die Suche nach dem passenden Werkzeug. Testen verschiedener Modelle (z.B. Lineare Regression vs. Random Forest).
*   *Ziel:* Den Algorithmus finden, der unser Problem am besten lÃ¶sen kann.

**A2 â€“ Adapting Features (Feature-Anpassung)**
*   Datenaufbereitung fÃ¼r Fortgeschrittene. Wir transformieren Rohdaten so, dass das Modell sie besser versteht (z.B. durch "Lag-Features" oder zeitliche Synchronisierung).
*   *Ziel:* Den Rohdiamanten schleifen, damit das Modell Muster leichter erkennt.

**A3 â€“ Adjusting Hyperparameters (Hyperparameter-Optimierung)**
*   Feinjustierung. Wir drehen an den Stellschrauben des gewÃ¤hlten Modells, um das letzte QuÃ¤ntchen Genauigkeit herauszuholen (z.B. RMSE unter 0,2â€¯Â°C drÃ¼cken).
*   *Ziel:* Maximale Performance und Robustheit.

**C â€“ Conclusion & Compare (Schlussfolgerung)**
*   Der RealitÃ¤tscheck. Wir bewerten das fertig trainierte Modell kritisch und vergleichen es mit Alternativen.
*   *Ziel:* Die Entscheidung fÃ¼r das finale Modellsetup, das in die App kommt.

**K â€“ Knowledge Transfer (Wissenstransfer)**
*   Vom Code zur Anwendung. Wir bauen die Streamlit-Web-App und dokumentieren unsere Ergebnisse verstÃ¤ndlich.
*   *Ziel:* Die komplexen Ergebnisse fÃ¼r den Endnutzer nutzbar machen (Dashboard, Karten, KPIs).
